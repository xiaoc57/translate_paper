# 3D Gaussian Splatting 用于实时渲染辐射场
辐射场方法最近已经彻底改变了在多张图片或视频中捕获的场景的新视角合成。然而，实现高视觉质量仍然需要神经网络进行训练和渲染，最近快速的方法不可避免地为以速度换质量。对于无界，完整的场景（而不是单个物体）且以1080p的分辨率渲染，没有一个最新的方法可以达到实时播放的速率。我们介绍了三个关键的元素，这些元素可以使我们在具有竞争力的训练时间的情况下达到最好的视觉质量，并且重要的是，这些元素允许在1080p分辨率的情况下实现高质量实时（>= 30fps）新视角合成。首先，从相机校准时产生的那些稀疏点开始，我们用3D Gaussian表示整个场景，它为场景优化保留了体积辐射场理想的特征，同时阻止了在空的空间内不必要的计算。第二点，我们对3D Gaussian实行交错优化/密度控制，特别是优化各向异性以实现对场景的精确表示。第三点，我们开发了一个快速可见渲染算法，这个算法支持各向异性抛洒并且同时加速训练和允许实时渲染。我们在很多已经建立的数据集上展示了最先进的视觉质量和实时渲染效果。

## INTRODUCTION
网格和点云是最常见的3D场景表示因为它们是显示的并且非常适合快速GPU/CUDA为基础的光栅化。不同的是，最近神经辐射场（NeRF）方法建立了连续场景表示，特别地，它优化了一个多层感知机（MLP）使用体素光线撞击（？？？？）为捕获的场景进行新视角合成。同样地，迄今为止的最有效的辐射场解决方案建立连续表示通过对体素或者是哈希网格或点进行插值。虽然这些方法的连续性有助于优化，但是渲染所需要的随机采样的成本高昂并且可能导致噪声。我们介绍一个新的方法用来最好的联系两个世界：我们的3D Gaussian表示允许最优的视觉质量和有竞争力的训练时间，而我们的基于瓷砖的泼洒（tile-based splatting）方法在很多从前的发布的数据集确保实时渲染在1080p分辨率且SOTA的质量下。  
我们的目标是为了使从多张图片中捕获的场景能够实时渲染并且创建这种表示的优化时间要和最有效的从前的典型真实场景的方法一样快。（？？这翻译的不是人话）最近的方法实现了快速训练，但是很难达到当前SOTA的NeRF方法如（Mip-NeRF360）所能达到的视觉质量，并且它需要48小时的训练时间。快速但是低质量辐射场方法可以根据场景达到可交互的渲染时间（10-15 帧每秒），但是达不到在高分辨率的情况下实时渲染。  
我们的解决方案建立在三个主要的组件中。我们首先介绍3D Gaussians作为一个可变形的并且可表达的场景表示。我们从和从前的NeRF方法相同的输入开始，相机标定使用Structure-from-MotiGaussian，这些点云是随着SfM过程生成的一部分。与大多数需要多视角立体（MVS）数据的基于点的方法不同的是我们实现了高质量的结果只适用SfM点作为输入。注意，对于NeRF合成数据集来说，我们的方法只适用随机的初始化也可以实现高质量。我们展示了3Don（SfM）方法并且用稀疏点云初始化一系列3D  Gaussian是一个明智的选择，因为它们是可微分的体积表示，但是他们也可以映射到2D被有效光栅化，并且应用标准alpha混合，使用了一个与NeRF等效的图像形成模型。第二个组件在我们的方法中是优化